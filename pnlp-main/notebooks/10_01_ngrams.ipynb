{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10: Words Sequences\n",
    "$N$-grams and collocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programs from the book: [_Python for Natural Language Processing_](https://link.springer.com/book/9783031575488)\n",
    "\n",
    "__Author__: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import regex as re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = 'HOMER'  # 'ILIAD' # 'HOMER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BOOK I\\n\\nSing, O goddess, the anger of Achilles son'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../datasets/classics/'\n",
    "if CORPUS == 'ILIAD':\n",
    "    text = open(PATH + 'iliad.txt').read().strip()\n",
    "elif CORPUS == 'HOMER':\n",
    "    text = open(PATH + 'iliad.txt').read().strip() + ' ' + \\\n",
    "        open(PATH + 'odyssey.txt').read().strip()\n",
    "\n",
    "text[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    words = re.findall(r'\\p{L}+', text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We analyze the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 15794), ('and', 11662), ('of', 8664), ('to', 6528), ('he', 4728)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = tokenize(text.lower())\n",
    "word_freqs = Counter(words)\n",
    "word_freqs.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend the counts to pairs of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tokenize(text.lower())\n",
    "bigrams = [tuple(words[idx:idx + 2])\n",
    "           for idx in range(len(words) - 1)]\n",
    "bigram_freqs = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('of', 'the'), 1873),\n",
       " (('to', 'the'), 1011),\n",
       " (('son', 'of'), 953),\n",
       " (('in', 'the'), 929),\n",
       " (('and', 'the'), 776),\n",
       " (('on', 'the'), 549),\n",
       " (('the', 'achaeans'), 519),\n",
       " (('as', 'he'), 488),\n",
       " (('he', 'was'), 485),\n",
       " (('the', 'trojans'), 481)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('of', 'the') \t 1873\n",
      "('to', 'the') \t 1011\n",
      "('son', 'of') \t 953\n",
      "('in', 'the') \t 929\n",
      "('and', 'the') \t 776\n",
      "('on', 'the') \t 549\n",
      "('the', 'achaeans') \t 519\n",
      "('as', 'he') \t 488\n",
      "('he', 'was') \t 485\n",
      "('the', 'trojans') \t 481\n",
      "('from', 'the') \t 434\n",
      "('of', 'his') \t 412\n",
      "('the', 'son') \t 397\n",
      "('for', 'the') \t 391\n",
      "('by', 'the') \t 388\n"
     ]
    }
   ],
   "source": [
    "for bigram in sorted(bigram_freqs.keys(), key=bigram_freqs.get, reverse=True)[:15]:\n",
    "    print(bigram, '\\t', bigram_freqs[bigram])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = [tuple(words[idx:idx + 3])\n",
    "            for idx in range(len(words) - 2)]\n",
    "trigram_freqs = Counter(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'son', 'of'), 389),\n",
       " (('of', 'the', 'achaeans'), 210),\n",
       " (('the', 'house', 'of'), 131),\n",
       " (('son', 'of', 'atreus'), 129),\n",
       " (('son', 'of', 'peleus'), 106),\n",
       " (('out', 'of', 'the'), 103),\n",
       " (('as', 'he', 'spoke'), 95),\n",
       " (('the', 'trojans', 'and'), 95),\n",
       " (('as', 'soon', 'as'), 93),\n",
       " (('as', 'he', 'was'), 92)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries do not guarantee the order. We can sort according to the frequency and then the lexical order using a `lambda` function to define the sorting key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 'son', 'of') \t 389\n",
      "('of', 'the', 'achaeans') \t 210\n",
      "('the', 'house', 'of') \t 131\n",
      "('son', 'of', 'atreus') \t 129\n",
      "('son', 'of', 'peleus') \t 106\n",
      "('out', 'of', 'the') \t 103\n",
      "('as', 'he', 'spoke') \t 95\n",
      "('the', 'trojans', 'and') \t 95\n",
      "('as', 'soon', 'as') \t 93\n",
      "('as', 'he', 'was') \t 92\n",
      "('even', 'so', 'did') \t 91\n",
      "('son', 'of', 'tydeus') \t 85\n",
      "('for', 'he', 'was') \t 83\n",
      "('to', 'the', 'ships') \t 79\n",
      "('of', 'the', 'trojans') \t 76\n",
      "('on', 'to', 'the') \t 74\n",
      "('in', 'the', 'house') \t 72\n",
      "('son', 'of', 'saturn') \t 72\n",
      "('to', 'the', 'ground') \t 70\n",
      "('when', 'they', 'had') \t 70\n",
      "('to', 'the', 'house') \t 67\n",
      "('when', 'he', 'had') \t 67\n",
      "('ships', 'of', 'the') \t 64\n",
      "('in', 'front', 'of') \t 63\n",
      "('the', 'city', 'of') \t 63\n",
      "('the', 'ships', 'of') \t 63\n",
      "('thus', 'did', 'he') \t 62\n",
      "('him', 'in', 'the') \t 61\n",
      "('the', 'body', 'of') \t 60\n",
      "('the', 'hands', 'of') \t 60\n"
     ]
    }
   ],
   "source": [
    "for trigram in sorted(trigram_freqs.keys(), key=lambda x: (-trigram_freqs.get(x), x))[:30]:\n",
    "    print(trigram, '\\t', trigram_freqs[trigram])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = [tuple(words[idx:idx + n])\n",
    "          for idx in range(len(words) - n + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'son', 'of'), 389),\n",
       " (('of', 'the', 'achaeans'), 210),\n",
       " (('the', 'house', 'of'), 131),\n",
       " (('son', 'of', 'atreus'), 129),\n",
       " (('son', 'of', 'peleus'), 106)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_freqs = Counter(ngrams)\n",
    "ngram_freqs.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 'son', 'of') \t 389\n",
      "('of', 'the', 'achaeans') \t 210\n",
      "('the', 'house', 'of') \t 131\n",
      "('son', 'of', 'atreus') \t 129\n",
      "('son', 'of', 'peleus') \t 106\n",
      "('out', 'of', 'the') \t 103\n",
      "('as', 'he', 'spoke') \t 95\n",
      "('the', 'trojans', 'and') \t 95\n",
      "('as', 'soon', 'as') \t 93\n",
      "('as', 'he', 'was') \t 92\n",
      "('even', 'so', 'did') \t 91\n",
      "('son', 'of', 'tydeus') \t 85\n",
      "('for', 'he', 'was') \t 83\n",
      "('to', 'the', 'ships') \t 79\n",
      "('of', 'the', 'trojans') \t 76\n"
     ]
    }
   ],
   "source": [
    "for ngram in sorted(ngram_freqs.keys(), key=lambda x: (-ngram_freqs.get(x), x))[:15]:\n",
    "    print(ngram, '\\t', ngram_freqs[ngram])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cooccurrence measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all the computations, we need this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqs = Counter(words)\n",
    "\n",
    "bigrams = [tuple(words[idx:idx + 2])\n",
    "           for idx in range(len(words) - 1)]\n",
    "bigram_freqs = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info(words, freq_unigrams, freq_bigrams):\n",
    "    mi = {}\n",
    "    factor = len(words) * len(words) / (len(words) - 1)\n",
    "    for bigram in freq_bigrams:\n",
    "        mi[bigram] = (\n",
    "            math.log(factor * freq_bigrams[bigram] /\n",
    "                     (freq_unigrams[bigram[0]] *\n",
    "                      freq_unigrams[bigram[1]]), 2))\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = mutual_info(words, word_freqs, bigram_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('abians', 'justest') \t 1 \t 1 \t 1 \t 18.05062986856374\n",
      "('acroneos', 'ocyalus') \t 1 \t 1 \t 1 \t 18.05062986856374\n",
      "('aesymnus', 'orus') \t 1 \t 1 \t 1 \t 18.05062986856374\n",
      "('agathon', 'pammon') \t 1 \t 1 \t 1 \t 18.05062986856374\n",
      "('agave', 'doto') \t 1 \t 1 \t 1 \t 18.05062986856374\n",
      "('aipy', 'cyparisseis') \t 1 \t 1 \t 1 \t 18.05062986856374\n",
      "('allotment', 'unplundered') \t 1 \t 1 \t 1 \t 18.05062986856374\n",
      "('alos', 'alope') \t 1 \t 1 \t 1 \t 18.05062986856374\n",
      "('amphoterus', 'epaltes') \t 1 \t 1 \t 1 \t 18.05062986856374\n",
      "('aretaon', 'ablerus') \t 1 \t 1 \t 1 \t 18.05062986856374\n",
      "('astypylus', 'mnesus') \t 1 \t 1 \t 1 \t 18.05062986856374\n",
      "('bessa', 'scarphe') \t 1 \t 1 \t 1 \t 18.05062986856374\n",
      "('blacksmith', 'plunges') \t 1 \t 1 \t 1 \t 18.05062986856374\n",
      "('bo', 'ies') \t 1 \t 1 \t 1 \t 18.05062986856374\n",
      "('boebe', 'glaphyrae') \t 1 \t 1 \t 1 \t 18.05062986856374\n"
     ]
    }
   ],
   "source": [
    "for bigram in sorted(mi.keys(), key=lambda x: (-mi.get(x), x))[:15]:\n",
    "    print(bigram, '\\t',\n",
    "          word_freqs[bigram[0]], '\\t',\n",
    "          word_freqs[bigram[1]], '\\t',\n",
    "          bigram_freqs[bigram], '\\t',\n",
    "          mi[bigram])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutual information is highly biased toward low-frequency words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 15\n",
    "filtered_mi = {k: v for k, v in mi.items() if bigram_freqs[k] >= cutoff}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('rosy', 'fingered') \t 25 \t 26 \t 25 \t 13.350190150422646\n",
      "('mixing', 'bowl') \t 33 \t 29 \t 17 \t 12.235717595328053\n",
      "('barley', 'meal') \t 29 \t 35 \t 18 \t 12.233290857933513\n",
      "('fingered', 'dawn') \t 26 \t 48 \t 22 \t 12.224659268338788\n",
      "('dawn', 'appeared') \t 48 \t 29 \t 21 \t 12.000003795493768\n",
      "('thigh', 'bones') \t 37 \t 47 \t 21 \t 11.67890507403591\n",
      "('outer', 'court') \t 36 \t 56 \t 24 \t 11.658312445784977\n",
      "('aegis', 'bearing') \t 45 \t 64 \t 32 \t 11.558776772234063\n",
      "('morning', 'rosy') \t 85 \t 25 \t 20 \t 11.319310837538673\n",
      "('ox', 'hide') \t 32 \t 53 \t 15 \t 11.229600009609058\n",
      "('single', 'handed') \t 57 \t 37 \t 15 \t 10.915177084378564\n",
      "('store', 'room') \t 42 \t 95 \t 20 \t 10.410384932341392\n",
      "('phoebus', 'apollo') \t 39 \t 170 \t 33 \t 10.400230832922242\n",
      "('drink', 'offering') \t 141 \t 41 \t 24 \t 10.138489012268018\n",
      "('drink', 'offerings') \t 141 \t 45 \t 25 \t 10.063081609609995\n"
     ]
    }
   ],
   "source": [
    "for bigram in sorted(filtered_mi.keys(), key=lambda x: (-filtered_mi.get(x), x))[:15]:\n",
    "    print(bigram, '\\t',\n",
    "          word_freqs[bigram[0]], '\\t',\n",
    "          word_freqs[bigram[1]], '\\t',\n",
    "          bigram_freqs[bigram], '\\t',\n",
    "          filtered_mi[bigram])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_ratio(words, word_freqs, bigram_freqs):\n",
    "    lr = {}\n",
    "    for bigram in bigram_freqs:\n",
    "        p = word_freqs[bigram[1]] / len(words)\n",
    "        p1 = bigram_freqs[bigram] / word_freqs[bigram[0]]\n",
    "        p2 = ((word_freqs[bigram[1]] - bigram_freqs[bigram])\n",
    "              / (len(words) - word_freqs[bigram[0]]))\n",
    "        if p1 != 1.0 and p2 != 0.0:\n",
    "            lr[bigram] = 2.0 * (\n",
    "                log_f(bigram_freqs[bigram],\n",
    "                      word_freqs[bigram[0]], p1) +\n",
    "                log_f(word_freqs[bigram[1]] -\n",
    "                      bigram_freqs[bigram],\n",
    "                      len(words) - word_freqs[bigram[0]], p2) -\n",
    "                log_f(bigram_freqs[bigram],\n",
    "                      word_freqs[bigram[0]], p) -\n",
    "                log_f(word_freqs[bigram[1]] -\n",
    "                      bigram_freqs[bigram],\n",
    "                      len(words) - word_freqs[bigram[0]], p))\n",
    "    return lr\n",
    "\n",
    "\n",
    "def log_f(k, N, p):\n",
    "    return k * math.log(p) + (N - k) * math.log(1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('son', 'of') \t 1290 \t 8664 \t 953 \t 5209.0273578509805\n",
      "('of', 'the') \t 8664 \t 15794 \t 1873 \t 2557.1296105680667\n",
      "('the', 'achaeans') \t 15794 \t 601 \t 519 \t 2499.2751029700266\n",
      "('i', 'am') \t 3195 \t 342 \t 294 \t 2363.33694579609\n",
      "('the', 'trojans') \t 15794 \t 573 \t 481 \t 2255.997249339922\n",
      "('the', 'the') \t 15794 \t 15794 \t 4 \t 1899.7875260145374\n",
      "('he', 'was') \t 4728 \t 2166 \t 485 \t 1729.0250078236386\n",
      "('at', 'once') \t 1207 \t 233 \t 176 \t 1674.4429057758052\n",
      "('as', 'he') \t 2578 \t 4728 \t 488 \t 1569.0800730942938\n",
      "('i', 'will') \t 3195 \t 1505 \t 340 \t 1474.440123164859\n",
      "('you', 'are') \t 3716 \t 1117 \t 321 \t 1463.38557310121\n",
      "('one', 'another') \t 993 \t 287 \t 161 \t 1441.477222814483\n",
      "('in', 'the') \t 3870 \t 15794 \t 929 \t 1405.7896939456114\n",
      "('even', 'so') \t 469 \t 1409 \t 175 \t 1247.0054785120046\n",
      "('let', 'us') \t 536 \t 610 \t 147 \t 1203.0767601206207\n"
     ]
    }
   ],
   "source": [
    "lr = likelihood_ratio(words, word_freqs, bigram_freqs)\n",
    "\n",
    "for bigram in sorted(lr, key=lambda x: (-lr.get(x), x))[:15]:\n",
    "    print(bigram, \"\\t\", word_freqs[bigram[0]], \"\\t\", word_freqs[bigram[1]], \"\\t\",\n",
    "          bigram_freqs[bigram], '\\t', lr[bigram])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_scores(words, word_freqs, bigram_freqs):\n",
    "    ts = {}\n",
    "    for bigram in bigram_freqs:\n",
    "        ts[bigram] = ((bigram_freqs[bigram] -\n",
    "                      word_freqs[bigram[0]] *\n",
    "                      word_freqs[bigram[1]] /\n",
    "                      len(words)) /\n",
    "                      math.sqrt(bigram_freqs[bigram]))\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('of', 'the') \t 8664 \t 15794 \t 1873 \t 31.632559609220863\n",
      "('son', 'of') \t 1290 \t 8664 \t 953 \t 29.537231081902494\n",
      "('in', 'the') \t 3870 \t 15794 \t 929 \t 23.09339064531879\n",
      "('the', 'achaeans') \t 15794 \t 601 \t 519 \t 21.246942166107083\n",
      "('the', 'trojans') \t 15794 \t 573 \t 481 \t 20.41188299332636\n",
      "('he', 'was') \t 4728 \t 2166 \t 485 \t 20.309998502446987\n",
      "('as', 'he') \t 2578 \t 4728 \t 488 \t 20.05850054978281\n",
      "('to', 'the') \t 6528 \t 15794 \t 1011 \t 19.853120651062955\n",
      "('on', 'the') \t 1941 \t 15794 \t 549 \t 18.611802965260487\n",
      "('i', 'will') \t 3195 \t 1505 \t 340 \t 17.478608590799595\n",
      "('he', 'had') \t 4728 \t 1731 \t 357 \t 17.299075188669896\n",
      "('you', 'are') \t 3716 \t 1117 \t 321 \t 17.06318232738217\n",
      "('i', 'am') \t 3195 \t 342 \t 294 \t 16.911711563645227\n",
      "('from', 'the') \t 1536 \t 15794 \t 434 \t 16.54363696048748\n",
      "('the', 'son') \t 15794 \t 1290 \t 397 \t 16.158626064246796\n"
     ]
    }
   ],
   "source": [
    "ts = t_scores(words, word_freqs, bigram_freqs)\n",
    "\n",
    "for bigram in sorted(ts, key=lambda x: (-ts.get(x), x))[:15]:\n",
    "    print(bigram, \"\\t\", word_freqs[bigram[0]], \"\\t\", word_freqs[bigram[1]], \"\\t\",\n",
    "          bigram_freqs[bigram], '\\t', ts[bigram])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
