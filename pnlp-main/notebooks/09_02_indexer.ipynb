{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9: Counting and Indexing Words\n",
    "Building an inverted index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programs from the book: [_Python for Natural Language Processing_](https://link.springer.com/book/9783031575488)\n",
    "\n",
    "__Author__: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program indexes all the words in a corpus. Conceptually, an index consists of rows with one word per row and the list of files and positions, where this word occurs. Such a row is called a _posting list_. We encode the position of a word by the number of characters from the start of the file.\n",
    "<pre>\n",
    "word1: file_name pos1 pos2 pos3... file_name pos1 pos2 ...\n",
    "word2: file_name pos1 pos2 pos3... file_name pos1 pos2 ...\n",
    "...\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to read the files with a certain suffix in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(dir, suffix):\n",
    "    \"\"\"\n",
    "    Returns all the files in a folder ending with suffix\n",
    "    :param dir:\n",
    "    :param suffix:\n",
    "    :return: the list of file names\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for file in os.listdir(dir):\n",
    "        if file.endswith(suffix):\n",
    "            files.append(file)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an index for a corpus of Dickens works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../datasets/dickens/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hard Times.txt',\n",
       " 'Oliver Twist.txt',\n",
       " 'Great Expectations.txt',\n",
       " 'The Old Curiosity Shop.txt',\n",
       " 'A Tale of Two Cities.txt',\n",
       " 'Dombey and Son.txt',\n",
       " 'The Pickwick Papers.txt',\n",
       " 'Bleak House.txt',\n",
       " 'Our Mutual Friend.txt',\n",
       " 'The Mystery of Edwin Drood.txt',\n",
       " 'Nicholas Nickleby.txt',\n",
       " 'David Copperfield.txt',\n",
       " 'Little Dorrit.txt',\n",
       " 'A Christmas Carol in Prose.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_files = get_files(folder, 'txt')\n",
    "corpus_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming the Indexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r'\\p{L}+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monsieur', 'the', 'Marquis', 'vendor', 'of', 'wine']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(regex, 'Monsieur the Marquis, vendor of wine.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    words = re.finditer(regex, text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<regex.Match object; span=(0, 8), match='Monsieur'>,\n",
       " <regex.Match object; span=(9, 12), match='the'>,\n",
       " <regex.Match object; span=(13, 20), match='Marquis'>,\n",
       " <regex.Match object; span=(22, 28), match='vendor'>,\n",
       " <regex.Match object; span=(29, 31), match='of'>,\n",
       " <regex.Match object; span=(32, 36), match='wine'>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize(\n",
    "    'Monsieur the Marquis, vendor of wine.')\n",
    "list(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `text_to_idx(words)` function extracts the indices from the list of tokens (words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_idx(words):\n",
    "    \"\"\"\n",
    "    Builds an index from a list of match objects\n",
    "    \"\"\"\n",
    "    word_idx = {}\n",
    "    for word in words:\n",
    "        try:\n",
    "            word_idx[word.group()].append(word.start())\n",
    "        except:\n",
    "            word_idx[word.group()] = [word.start()]\n",
    "    return word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monsieur': [0],\n",
       " 'the': [9],\n",
       " 'marquis': [13],\n",
       " 'vendor': [22],\n",
       " 'of': [29],\n",
       " 'wine': [32]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize(\n",
    "    'Monsieur the Marquis, vendor of wine.'.lower().strip())\n",
    "text_to_idx(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading one file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read one file, _A Tale of Two Cities_, `A Tale of Two Cities.txt`, set it in lowercase, tokenize it, and index it. We call this index `idx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_file = folder + 'A Tale of Two Cities.txt'\n",
    "text = open(first_file, encoding='utf-8').read().lower().strip()\n",
    "words = tokenize(text)\n",
    "idx = text_to_idx(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[218582, 218631, 219234, 635168]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx['vendor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save index in a file with the pickle module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_file = 'a_tale_of_two_cities.idx'\n",
    "pickle.dump(idx, open(index_file, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read back your file and we store the content in `idx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pickle.load(open(index_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[218582, 218631, 219234, 635168]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx['vendor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the content of a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hard Times.txt',\n",
       " 'Oliver Twist.txt',\n",
       " 'Great Expectations.txt',\n",
       " 'The Old Curiosity Shop.txt',\n",
       " 'A Tale of Two Cities.txt',\n",
       " 'Dombey and Son.txt',\n",
       " 'The Pickwick Papers.txt',\n",
       " 'Bleak House.txt',\n",
       " 'Our Mutual Friend.txt',\n",
       " 'The Mystery of Edwin Drood.txt',\n",
       " 'Nicholas Nickleby.txt',\n",
       " 'David Copperfield.txt',\n",
       " 'Little Dorrit.txt',\n",
       " 'A Christmas Carol in Prose.txt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_files = get_files(folder, 'txt')\n",
    "corpus_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a master index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word <i>vendor</i>, for instance, occurs four times in _A Tale of Two Cities_ at positions\n",
    "            218582, 218631, 219234, and 635168."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_index = {}\n",
    "for file in corpus_files:\n",
    "    text = open(folder + file, encoding='utf-8').read().lower().strip()\n",
    "    words = tokenize(text)\n",
    "    idx = text_to_idx(words)\n",
    "    for word in idx:\n",
    "        if word in master_index:\n",
    "            master_index[word][file] = idx[word]\n",
    "        else:\n",
    "            master_index[word] = {}\n",
    "            master_index[word][file] = idx[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Oliver Twist.txt': [788457],\n",
       " 'A Tale of Two Cities.txt': [218582, 218631, 219234, 635168],\n",
       " 'Dombey and Son.txt': [1080291],\n",
       " 'The Pickwick Papers.txt': [28715],\n",
       " 'Bleak House.txt': [1474429]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_index['vendor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hard Times.txt': [206688, 329331, 330018],\n",
       " 'Oliver Twist.txt': [117173, 152567, 257637, 568782, 673524],\n",
       " 'Great Expectations.txt': [272920, 321608, 648710, 982503],\n",
       " 'The Old Curiosity Shop.txt': [7177, 57252, 187226],\n",
       " 'A Tale of Two Cities.txt': [269196, 618140, 669252],\n",
       " 'Dombey and Son.txt': [100181,\n",
       "  328794,\n",
       "  498361,\n",
       "  622188,\n",
       "  622246,\n",
       "  766143,\n",
       "  912596,\n",
       "  1204627],\n",
       " 'The Pickwick Papers.txt': [85832,\n",
       "  425008,\n",
       "  425370,\n",
       "  533925,\n",
       "  650753,\n",
       "  1343247,\n",
       "  1592405,\n",
       "  1629557,\n",
       "  1673972],\n",
       " 'Bleak House.txt': [962433, 1662029, 1840382, 1897369],\n",
       " 'Our Mutual Friend.txt': [91952,\n",
       "  92020,\n",
       "  410589,\n",
       "  414573,\n",
       "  683351,\n",
       "  835951,\n",
       "  888199,\n",
       "  926327,\n",
       "  969205,\n",
       "  1254188,\n",
       "  1258422,\n",
       "  1318630,\n",
       "  1457539,\n",
       "  1466035,\n",
       "  1490735,\n",
       "  1673403,\n",
       "  1737036,\n",
       "  1794595],\n",
       " 'Nicholas Nickleby.txt': [411260,\n",
       "  790675,\n",
       "  1168530,\n",
       "  1197303,\n",
       "  1240532,\n",
       "  1391071,\n",
       "  1457691,\n",
       "  1766702],\n",
       " 'David Copperfield.txt': [533653,\n",
       "  597133,\n",
       "  699197,\n",
       "  819121,\n",
       "  1161620,\n",
       "  1297435,\n",
       "  1297468,\n",
       "  1522835,\n",
       "  1827882,\n",
       "  1901359],\n",
       " 'Little Dorrit.txt': [500613,\n",
       "  1086670,\n",
       "  1101995,\n",
       "  1509278,\n",
       "  1533564,\n",
       "  1619364,\n",
       "  1619458,\n",
       "  1870557]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_index['deserve']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the master index in a file and read it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(master_index, open('master.idx', 'wb'))\n",
    "master_index = pickle.load(open('master.idx', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Oliver Twist.txt': [788457],\n",
       " 'A Tale of Two Cities.txt': [218582, 218631, 219234, 635168],\n",
       " 'Dombey and Son.txt': [1080291],\n",
       " 'The Pickwick Papers.txt': [28715],\n",
       " 'Bleak House.txt': [1474429]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_index['vendor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concordances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `concordance(word, master_index, window)` function extracts the concordances of a `word` within a window of `window` characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance(word, master_index, window):\n",
    "    for document in master_index[word].keys():\n",
    "        print(document)\n",
    "        text = open(folder + document, encoding='utf-8').read().lower().strip()\n",
    "        for idx in master_index[word][document]:\n",
    "            if idx - window < 0:\n",
    "                idx_left = 0\n",
    "            else:\n",
    "                idx_left = idx - window\n",
    "            if idx + window > len(text):\n",
    "                idx_right = len(text)\n",
    "            else:\n",
    "                idx_right = idx + window\n",
    "            concordance = re.sub('\\s', ' ', text[idx_left:idx_right])\n",
    "            print('\\t' + concordance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oliver Twist.txt\n",
      "\t plainly hesitated.  the vendor observing this, in\n",
      "A Tale of Two Cities.txt\n",
      "\t  “monsieur the marquis, vendor of wine.”  “pick u\n",
      "\tup that, philosopher and vendor of wine,” said the\n",
      "\te spot where defarge the vendor of wine had stood,\n",
      "\tes. ernest defarge, wine-vendor of st. antoine.”  \n",
      "Dombey and Son.txt\n",
      "\teral garments, which the vendor declared to be suc\n",
      "The Pickwick Papers.txt\n",
      "\torcing the heated pastry-vendor’s proposition: and\n",
      "Bleak House.txt\n",
      "\tariably, taken in by the vendor and installed in t\n"
     ]
    }
   ],
   "source": [
    "concordance('vendor', master_index, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representing Documents with tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created the index, we can represent each document in your corpus as a dictionary. The keys of these dictionaries are the words and we define the value of a word with the tf-idf metric.\n",
    "\n",
    "As definition of tf-idf, we use this one: \n",
    " * Tf is the relative frequency of the term in the document and \n",
    " * idf, the logarithm base 10 of the inverse document frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptually, the tf-idf representation is a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = {}\n",
    "for file in corpus_files:\n",
    "    tfidf[file] = {}\n",
    "    total_words = 0\n",
    "    for word in master_index:\n",
    "        idf = math.log(len(corpus_files) / len(master_index[word]), 10)\n",
    "        if file in master_index[word]:\n",
    "            tf = len(master_index[word][file])\n",
    "            tfidf[file][word] = tf * idf\n",
    "            total_words += tf\n",
    "        else:\n",
    "            tfidf[file][word] = 0\n",
    "    for word in tfidf[file]:\n",
    "        tfidf[file][word] /= total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2924669774106877e-05"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf['A Tale of Two Cities.txt']['vendor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.451274081696086e-06"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf['A Tale of Two Cities.txt']['deserve']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the cosine similarity, we compare all the pairs of documents with their tf-idf representation. We compute it with `cosine_similarity(document1, document2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(document1, document2):\n",
    "    scalar_prod = 0.0\n",
    "    norm1 = 0.0\n",
    "    norm2 = 0.0\n",
    "    for word in tfidf[document1]:\n",
    "        scalar_prod += tfidf[document1][word] * tfidf[document2][word]\n",
    "        norm1 += tfidf[document1][word] * tfidf[document1][word]\n",
    "    for word in tfidf[document2]:\n",
    "        norm2 += tfidf[document2][word] * tfidf[document2][word]\n",
    "    # print(document1, document2, scalar_prod, math.sqrt(norm1), math.sqrt(norm2), '\\n')\n",
    "    return scalar_prod / (math.sqrt(norm1) * math.sqrt(norm2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the similarity matrix between the documents of the corpus. While computing the similarities, we record the two most similar documents `most_sim_doc1` and `most_sim_doc2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hard Times.txt', 'Oliver Twist.txt', 'Great Expectations.txt', 'The Old Curiosity Shop.txt', 'A Tale of Two Cities.txt', 'Dombey and Son.txt', 'The Pickwick Papers.txt', 'Bleak House.txt', 'Our Mutual Friend.txt', 'The Mystery of Edwin Drood.txt', 'Nicholas Nickleby.txt', 'David Copperfield.txt', 'Little Dorrit.txt', 'A Christmas Carol in Prose.txt']\n",
      "Hard Times.txt\t1.0000\t0.0005\t0.0009\t0.0008\t0.0007\t0.0054\t0.0015\t0.0023\t0.0009\t0.0010\t0.0009\t0.0011\t0.0005\t0.0002\t\n",
      "Oliver Twist.txt\t0.0005\t1.0000\t0.0009\t0.0021\t0.0007\t0.0007\t0.0010\t0.0030\t0.0018\t0.0016\t0.0006\t0.0020\t0.0006\t0.0003\t\n",
      "Great Expectations.txt\t0.0009\t0.0009\t1.0000\t0.0015\t0.0011\t0.0008\t0.0008\t0.0028\t0.0015\t0.0009\t0.0007\t0.0012\t0.0013\t0.0003\t\n",
      "The Old Curiosity Shop.txt\t0.0008\t0.0021\t0.0015\t1.0000\t0.0022\t0.0010\t0.0016\t0.0086\t0.0046\t0.0013\t0.0011\t0.0028\t0.0013\t0.0014\t\n",
      "A Tale of Two Cities.txt\t0.0007\t0.0007\t0.0011\t0.0022\t1.0000\t0.0013\t0.0012\t0.0012\t0.0008\t0.0008\t0.0025\t0.0008\t0.0035\t0.0003\t\n",
      "Dombey and Son.txt\t0.0054\t0.0007\t0.0008\t0.0010\t0.0013\t1.0000\t0.0009\t0.0026\t0.0010\t0.0010\t0.0015\t0.0015\t0.0019\t0.0003\t\n",
      "The Pickwick Papers.txt\t0.0015\t0.0010\t0.0008\t0.0016\t0.0012\t0.0009\t1.0000\t0.0016\t0.0022\t0.0006\t0.0014\t0.0014\t0.0009\t0.0015\t\n",
      "Bleak House.txt\t0.0023\t0.0030\t0.0028\t0.0086\t0.0012\t0.0026\t0.0016\t1.0000\t0.0042\t0.0080\t0.0017\t0.0020\t0.0013\t0.0004\t\n",
      "Our Mutual Friend.txt\t0.0009\t0.0018\t0.0015\t0.0046\t0.0008\t0.0010\t0.0022\t0.0042\t1.0000\t0.0013\t0.0007\t0.0017\t0.0012\t0.0004\t\n",
      "The Mystery of Edwin Drood.txt\t0.0010\t0.0016\t0.0009\t0.0013\t0.0008\t0.0010\t0.0006\t0.0080\t0.0013\t1.0000\t0.0008\t0.0052\t0.0008\t0.0003\t\n",
      "Nicholas Nickleby.txt\t0.0009\t0.0006\t0.0007\t0.0011\t0.0025\t0.0015\t0.0014\t0.0017\t0.0007\t0.0008\t1.0000\t0.0010\t0.0048\t0.0040\t\n",
      "David Copperfield.txt\t0.0011\t0.0020\t0.0012\t0.0028\t0.0008\t0.0015\t0.0014\t0.0020\t0.0017\t0.0052\t0.0010\t1.0000\t0.0012\t0.0004\t\n",
      "Little Dorrit.txt\t0.0005\t0.0006\t0.0013\t0.0013\t0.0035\t0.0019\t0.0009\t0.0013\t0.0012\t0.0008\t0.0048\t0.0012\t1.0000\t0.0003\t\n",
      "A Christmas Carol in Prose.txt\t0.0002\t0.0003\t0.0003\t0.0014\t0.0003\t0.0003\t0.0015\t0.0004\t0.0004\t0.0003\t0.0040\t0.0004\t0.0003\t1.0000\t\n"
     ]
    }
   ],
   "source": [
    "max_similarity = 0.0\n",
    "most_sim_doc1 = ''\n",
    "most_sim_doc2 = ''\n",
    "print(corpus_files)\n",
    "for doc1 in corpus_files:\n",
    "    print(doc1, end='\\t')\n",
    "    for doc2 in corpus_files:\n",
    "        cos_similarity = cosine_similarity(doc1, doc2)\n",
    "        print(\"%1.4f\" % cos_similarity, end='\\t')\n",
    "        if cos_similarity > max_similarity and doc1 != doc2:\n",
    "            max_similarity = cos_similarity\n",
    "            most_sim_doc1 = doc1\n",
    "            most_sim_doc2 = doc2\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar: The Old Curiosity Shop.txt Bleak House.txt Similarity: 0.008569236177211179\n"
     ]
    }
   ],
   "source": [
    "print(\"Most similar:\", most_sim_doc1,\n",
    "      most_sim_doc2, \"Similarity:\", max_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
